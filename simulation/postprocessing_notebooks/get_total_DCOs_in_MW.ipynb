{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-size:50px\">Rate Normalisation</h1>\n",
    "<p style=\"text-align:center\">After meeting with Floor, I should now have all the pieces to normalise the rates correctly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from compas_processing import mask_COMPAS_data, get_COMPAS_vars\n",
    "from galaxy import simulate_mw, simulate_simple_mw\n",
    "from variations import variations\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('font', family='serif')\n",
    "fs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - IMF related functions\n",
    "## 1.1 - Normalised IMF function\n",
    "\n",
    "We define the initial mass function as follows (using Kroupa)\n",
    "$$\n",
    "    \\zeta(m) = \\begin{cases} \n",
    "                    \\beta_1 m^{-\\alpha_1} & m_1 < m \\le m_2 \\\\\n",
    "                    \\beta_2 m^{-\\alpha_2} & m_2 < m \\le m_3 \\\\\n",
    "                    \\beta_3 m^{-\\alpha_3} & m_3 < m \\le m_4 \\\\\n",
    "                    0 & \\mathrm{else} \\\\\n",
    "               \\end{cases},\n",
    "$$\n",
    "where we define $m_i = [0.01, 0.08, 0.5, 200] \\ {\\rm M_\\odot}$ and $\\alpha_i = [0.3, 1.3, 2.3]$. The values of each $\\beta$ are defined such that the function is continuous and normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF(m, m1=0.01, m2=0.08, m3=0.5, m4=200.0, a12=0.3, a23=1.3, a34=2.3):\n",
    "    \"\"\" \n",
    "        Calculate the fraction of stellar mass between m and m + dm for a three part broken power law.\n",
    "        Default values follow Kroupa (2001)\n",
    "            zeta(m) ~ m^(-a_ij)\n",
    "        \n",
    "        Args:\n",
    "            m       --> [float, list of floats] mass or masses at which to evaluate\n",
    "            mi      --> [float]                 masses at which to transition the slope\n",
    "            aij     --> [float]                 slope of the IMF between mi and mj\n",
    "            \n",
    "        Returns:\n",
    "            zeta(m) --> [float, list of floats] value or values of the IMF at m\n",
    "    \"\"\"\n",
    "    # calculate normalisation constants that ensure the IMF is continuous\n",
    "    b1 = 1 / ( \n",
    "                (m2**(1 - a12) - m1**(1 - a12)) / (1 - a12) \\\n",
    "                + m2**(-(a12 - a23)) * (m3**(1 - a23) - m2**(1 - a23)) / (1 - a23) \\\n",
    "                + m2**(-(a12 - a23)) * m3**(-(a23 - a34)) * (m4**(1 - a34) - m3**(1 - a34)) / (1 - a34)\n",
    "             )\n",
    "    b2 = b1 * m2**(-(a12 - a23))\n",
    "    b3 = b2 * m3**(-(a23 - a34))\n",
    "    \n",
    "    # evaluate IMF either at a point or for a list of points\n",
    "    if isinstance(m, float):\n",
    "        if m < m1:\n",
    "            return 0\n",
    "        elif m < m2:\n",
    "            return b1 * m**(-a12)\n",
    "        elif m < m3:\n",
    "            return b2 * m**(-a23)\n",
    "        elif m < m4:\n",
    "            return b3 * m**(-a34)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        imf_vals = np.zeros(len(m))\n",
    "        imf_vals[np.logical_and(m >= m1, m < m2)] = b1 * m[np.logical_and(m >= m1, m < m2)]**(-a12)\n",
    "        imf_vals[np.logical_and(m >= m2, m < m3)] = b2 * m[np.logical_and(m >= m2, m < m3)]**(-a23)\n",
    "        imf_vals[np.logical_and(m >= m3, m < m4)] = b3 * m[np.logical_and(m >= m3, m < m4)]**(-a34)\n",
    "        return imf_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Cumulative density function of the IMF\n",
    "The CDF is defined as $F(m) = \\int_{-\\infty}^{m} \\zeta(m) \\ \\mathrm{d}m$ and we so we take the same function as above but integrate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF_IMF(m, m1=0.01, m2=0.08, m3=0.5, m4=200.0, a12=0.3, a23=1.3, a34=2.3):\n",
    "    \"\"\" \n",
    "        Calculate the fraction of stellar mass between 0 and m for a three part broken power law.\n",
    "        Default values follow Kroupa (2001)\n",
    "            F(m) ~ int_0^m zeta(m) dm\n",
    "        \n",
    "        Args:\n",
    "            m       --> [float, list of floats] mass or masses at which to evaluate\n",
    "            mi      --> [float]                 masses at which to transition the slope\n",
    "            aij     --> [float]                 slope of the IMF between mi and mj\n",
    "            \n",
    "        Returns:\n",
    "            zeta(m) --> [float, list of floats] value or values of the IMF at m\n",
    "\n",
    "        NOTE: this is implemented recursively, probably not the most efficient if you're using this intensively but I'm not so I'm being lazy ¯\\_(ツ)_/¯ \n",
    "    \"\"\"\n",
    "\n",
    "    # calculate normalisation constants that ensure the IMF is continuous\n",
    "    b1 = 1 / ( \n",
    "                (m2**(1 - a12) - m1**(1 - a12)) / (1 - a12) \\\n",
    "                + m2**(-(a12 - a23)) * (m3**(1 - a23) - m2**(1 - a23)) / (1 - a23) \\\n",
    "                + m2**(-(a12 - a23)) * m3**(-(a23 - a34)) * (m4**(1 - a34) - m3**(1 - a34)) / (1 - a34)\n",
    "             )\n",
    "    b2 = b1 * m2**(-(a12 - a23))\n",
    "    b3 = b2 * m3**(-(a23 - a34))\n",
    "    \n",
    "    if isinstance(m, float):\n",
    "        if m <= m1:\n",
    "            return 0\n",
    "        elif m <= m2:\n",
    "            return b1 / (1 - a12) * (m**(1 - a12) - m1**(1 - a12))\n",
    "        elif m <= m3:\n",
    "            return CDF_IMF(m2) + b2 / (1 - a23) * (m**(1 - a23) - m2**(1 - a23))\n",
    "        elif m <= m4:\n",
    "            return CDF_IMF(m3) + b3 / (1 - a34) * (m**(1 - a34) - m3**(1 - a34))\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        CDF = np.zeros(len(m))\n",
    "        CDF[np.logical_and(m >= m1, m < m2)] = b1 / (1 - a12) * (m[np.logical_and(m >= m1, m < m2)]**(1 - a12) - m1**(1 - a12))\n",
    "        CDF[np.logical_and(m >= m2, m < m3)] = CDF_IMF(m2) + b2 / (1 - a23) * (m[np.logical_and(m >= m2, m < m3)]**(1 - a23) - m2**(1 - a23))\n",
    "        CDF[np.logical_and(m >= m3, m < m4)] = CDF_IMF(m3) + b3 / (1 - a34) * (m[np.logical_and(m >= m3, m < m4)]**(1 - a34) - m3**(1 - a34))\n",
    "        CDF[m >= m4] = np.ones(len(m[m >= m4]))\n",
    "        return CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Inverse CDF of IMF (for sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_CDF_IMF(U, m1=0.01, m2=0.08, m3=0.5, m4=200, a12=0.3, a23=1.3, a34=2.3):\n",
    "    \"\"\" \n",
    "        Calculate the inverse CDF for a three part broken power law.\n",
    "        Default values follow Kroupa (2001)\n",
    "        \n",
    "        Args:\n",
    "            U       --> [float, list of floats] A fraction between \n",
    "            mi      --> [float]                 masses at which to transition the slope\n",
    "            aij     --> [float]                 slope of the IMF between mi and mj\n",
    "            \n",
    "        Returns:\n",
    "            zeta(m) --> [float, list of floats] value or values of the IMF at m\n",
    "\n",
    "        NOTE: this is implemented recursively, probably not the most efficient if you're using this intensively but I'm not so I'm being lazy ¯\\_(ツ)_/¯ \n",
    "    \"\"\"\n",
    "\n",
    "    # calculate normalisation constants that ensure the IMF is continuous\n",
    "    b1 = 1 / ( \n",
    "                (m2**(1 - a12) - m1**(1 - a12)) / (1 - a12) \\\n",
    "                + m2**(-(a12 - a23)) * (m3**(1 - a23) - m2**(1 - a23)) / (1 - a23) \\\n",
    "                + m2**(-(a12 - a23)) * m3**(-(a23 - a34)) * (m4**(1 - a34) - m3**(1 - a34)) / (1 - a34)\n",
    "             )\n",
    "    b2 = b1 * m2**(-(a12 - a23))\n",
    "    b3 = b2 * m3**(-(a23 - a34))\n",
    "\n",
    "    # find the probabilities at which the gradient changes\n",
    "    F1, F2, F3, F4 = CDF_IMF(np.array([m1, m2, m3, m4]), m1=0.01, m2=0.08, m3=0.5, m4=200, a12=0.3, a23=1.3, a34=2.3)\n",
    "\n",
    "    masses = np.zeros(len(U))\n",
    "    masses[np.logical_and(U > F1, U <= F2)] = np.power((1 - a12) / b1 * (U[np.logical_and(U > F1, U <= F2)] - F1) + m1**(1 - a12), 1 / (1 - a12))\n",
    "    masses[np.logical_and(U > F2, U <= F3)] = np.power((1 - a23) / b2 * (U[np.logical_and(U > F2, U <= F3)] - F2) + m2**(1 - a23), 1 / (1 - a23))\n",
    "    masses[np.logical_and(U > F3, U <= F4)] = np.power((1 - a34) / b3 * (U[np.logical_and(U > F3, U <= F4)] - F3) + m3**(1 - a34), 1 / (1 - a34))\n",
    "    return masses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Main normalisation functions\n",
    "## 2.1 - Metallicity weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metallicity_weights(compas_grid, simple_mw=False):\n",
    "    # find the bins that have the COMPAS grid at its centre\n",
    "    inner_bins = np.array([compas_grid[i] + (compas_grid[i+1] - compas_grid[i]) / 2 for i in range(len(compas_grid) - 1)])\n",
    "    bins = np.concatenate(([compas_grid[0]], inner_bins, [compas_grid[-1]]))\n",
    "    \n",
    "    # sample from the chosen MW metallicity distribution\n",
    "    if simple_mw:\n",
    "        SAMPLE_SIZE = 2000000\n",
    "        _, _, sampled_Z = simulate_mw(SAMPLE_SIZE)\n",
    "    else:\n",
    "        SAMPLE_SIZE = 20000000\n",
    "        _, _, sampled_Z = simulate_mw(SAMPLE_SIZE)\n",
    "    \n",
    "    # adjust the sample so everything falls inside the compas grid\n",
    "    sampled_Z = sampled_Z.value\n",
    "    sampled_Z[sampled_Z > np.max(compas_grid)] = np.max(compas_grid)\n",
    "    sampled_Z[sampled_Z < np.min(compas_grid)] = np.min(compas_grid)\n",
    "    \n",
    "    # create a histogram on the grid and divide by the number of samples to find the weights\n",
    "    h, _ = np.histogram(sampled_Z, bins=bins)\n",
    "    w_Z = h / SAMPLE_SIZE\n",
    "    return w_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Find fraction of Universe simulated and average COMPAS mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_universe(m1_min, m1_max, m2_min, fbin, SAMPLES=20000000):\n",
    "    # randomly sample a large number of masses, binaries and mass ratios\n",
    "    primary_mass = inverse_CDF_IMF(np.random.rand(SAMPLES))\n",
    "    binary = np.random.rand(SAMPLES)\n",
    "    mass_ratio = np.random.rand(SAMPLES)\n",
    "\n",
    "    # only fbin fraction of stars have a secondary (in a binary). Assign each a random secondary mass using uniform mass ratio\n",
    "    secondary_mass = np.zeros(SAMPLES)\n",
    "    binary_mask = binary < fbin\n",
    "    secondary_mass[binary_mask] = primary_mass[binary_mask] * mass_ratio[binary_mask]\n",
    "\n",
    "    # find the total mass of the whole population\n",
    "    total_mass = np.sum(primary_mass) + np.sum(secondary_mass)\n",
    "\n",
    "    # apply the COMPAS cuts on primary and secondary mass\n",
    "    primary_mask = np.logical_and(primary_mass >= m1_min, primary_mass <= m1_max)\n",
    "    secondary_mask = secondary_mass > m2_min\n",
    "    full_mask = np.logical_and(primary_mask, secondary_mask)\n",
    "    total_mass_COMPAS = np.sum(primary_mass[full_mask]) + np.sum(secondary_mass[full_mask])\n",
    "\n",
    "    fraction = total_mass_COMPAS / total_mass\n",
    "    average_mass_COMPAS = total_mass_COMPAS / len(primary_mass[full_mask])\n",
    "    \n",
    "    return fraction, average_mass_COMPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Get star forming mass per Z for each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_forming_mass_per_Z(average_mass_COMPAS, file_path, compas_grid, binary_type, pessimistic=True, hubble_time=True):\n",
    "    # open COMPAS file\n",
    "    with h5.File(file_path, \"r\") as f:\n",
    "        # get a mask for the DCOs that you want\n",
    "        DCO_mask = mask_COMPAS_data(f, binary_type, (hubble_time, True, pessimistic))\n",
    "        DCO_weights, DCO_Z = get_COMPAS_vars(f, \"doubleCompactObjects\", [\"weight\", \"Metallicity1\"], DCO_mask)\n",
    "        \n",
    "        # sum the weights of the DCOs for each metallicity\n",
    "        total_BHNS_per_Z = np.array([np.sum(DCO_weights[DCO_Z == Z]) for Z in compas_grid])\n",
    "        \n",
    "        all_weights, all_Z = get_COMPAS_variable(f, \"systems\", [\"weight\", \"Metallicity1\"])\n",
    "        \n",
    "        # sum the weights of the binaries for each metallicity and multiply by average mass\n",
    "        MSF_per_Z_COMPAS = np.array([np.sum(all_weights[all_Z == Z]) * average_mass_COMPAS for Z in compas_grid])\n",
    "        \n",
    "    return MSF_per_Z_COMPAS, total_BHNS_per_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Put it all together to get the total DCOs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_DCO_in_MW(model, binary_type=\"BHNS\", w_Z=None, f_mass_sampled=None, average_mass_COMPAS=None, compas_grid=None, hubble_time=True):\n",
    "    # find the weight for each metallicity distribution using Frankel Model\n",
    "    if compas_grid is None:\n",
    "        compas_grid = np.concatenate((np.round(np.logspace(np.log10(0.0001), np.log10(0.022), 50), 5), [0.0244, 0.02705, 0.03]))\n",
    "    if w_Z is None:\n",
    "        w_Z = find_metallicity_weights(compas_grid)\n",
    "    \n",
    "    # sample from mass distributions for fraction and average mass\n",
    "    if f_mass_sampled is None or average_mass_COMPAS is None:\n",
    "        f_mass_sampled, average_mass_COMPAS = create_sample_universe(5, 150, 0.1, 0.7)\n",
    "    \n",
    "    # create a filepath to the particular model\n",
    "    pessimistic = True\n",
    "    if model == \"optimistic\" or model == \"unstableCaseBB_opt\":\n",
    "        model = \"fiducial\"\n",
    "        pessimistic = False\n",
    "    elif model == \"unstableCaseBB_opt\":\n",
    "        model = \"unstableCaseBB\"\n",
    "        pessimistic = False\n",
    "    file_path = \"/n/holystore01/LABS/berger_lab/Lab/fbroekgaarden/DATA/all_dco_legacy_CEbug_fix/{}/COMPASOutputCombined.h5\".format(model)\n",
    "    \n",
    "    # find the mass and total DCOs\n",
    "    MSF_per_Z_COMPAS, total_DCO_per_Z = star_forming_mass_per_Z(average_mass_COMPAS, file_path, compas_grid, binary_type, pessimistic=pessimistic, hubble_time=hubble_time)\n",
    "    MSF_per_Z = MSF_per_Z_COMPAS / f_mass_sampled\n",
    "    \n",
    "    M_MW = 9.1e10\n",
    "    \n",
    "    total_DCO_in_MW = np.sum(total_DCO_per_Z / MSF_per_Z * w_Z) * M_MW\n",
    "    \n",
    "    return total_DCO_in_MW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Actual calculations/execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_grid = np.concatenate((np.round(np.logspace(np.log10(0.0001), np.log10(0.022), 50), 5), [0.0244, 0.02705, 0.03]))\n",
    "w_Z = find_metallicity_weights(compas_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16027916907780462\n"
     ]
    }
   ],
   "source": [
    "f_mass_sampled, average_mass_COMPAS = create_sample_universe(5, 150, 0.1, 0.5)\n",
    "print(f_mass_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20746704309483271\n"
     ]
    }
   ],
   "source": [
    "f_mass_sampled, average_mass_COMPAS = create_sample_universe(5, 150, 0.1, 0.7)\n",
    "print(f_mass_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26858530838169276\n"
     ]
    }
   ],
   "source": [
    "f_mass_sampled, average_mass_COMPAS = create_sample_universe(5, 150, 0.1, 1.0)\n",
    "print(f_mass_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCO: BHBH, Model: fiducial, total: 164270.97465727743\n",
      "DCO: BHBH, Model: massTransferEfficiencyFixed_0_25, total: 167220.17804356778\n",
      "DCO: BHBH, Model: massTransferEfficiencyFixed_0_5, total: 124735.5130911542\n",
      "DCO: BHBH, Model: massTransferEfficiencyFixed_0_75, total: 110853.6323692181\n",
      "DCO: BHBH, Model: unstableCaseBB, total: 162450.9499088693\n",
      "DCO: BHBH, Model: alpha0_5, total: 132956.22162999658\n",
      "DCO: BHBH, Model: alpha2_0, total: 131368.57031165785\n",
      "DCO: BHBH, Model: optimistic, total: 529016.172641341\n",
      "DCO: BHBH, Model: rapid, total: 144566.9361740863\n",
      "DCO: BHBH, Model: maxNSmass2_0, total: 216973.61571558678\n",
      "DCO: BHBH, Model: maxNSmass3_0, total: 129490.94985153819\n",
      "DCO: BHBH, Model: noPISN, total: 164285.35701972753\n",
      "DCO: BHBH, Model: ccSNkick_100km_s, total: 219176.59564422868\n",
      "DCO: BHBH, Model: ccSNkick_30km_s, total: 262420.8098252059\n",
      "DCO: BHBH, Model: noBHkick, total: 251069.4165240384\n",
      "DCO: BHBH, Model: wolf_rayet_multiplier_0_1, total: 309175.2995330647\n",
      "DCO: BHBH, Model: wolf_rayet_multiplier_5, total: 23368.215511822476\n",
      "DCO: BHNS, Model: fiducial, total: 197150.38283667318\n",
      "DCO: BHNS, Model: massTransferEfficiencyFixed_0_25, total: 99536.30636969881\n",
      "DCO: BHNS, Model: massTransferEfficiencyFixed_0_5, total: 37383.834985346955\n",
      "DCO: BHNS, Model: massTransferEfficiencyFixed_0_75, total: 21080.375994665705\n",
      "DCO: BHNS, Model: unstableCaseBB, total: 50319.72957107211\n",
      "DCO: BHNS, Model: alpha0_5, total: 109321.33981444244\n",
      "DCO: BHNS, Model: alpha2_0, total: 141200.8373899666\n",
      "DCO: BHNS, Model: optimistic, total: 276445.8980078674\n",
      "DCO: BHNS, Model: rapid, total: 419843.899786546\n",
      "DCO: BHNS, Model: maxNSmass2_0, total: 149720.13215608988\n",
      "DCO: BHNS, Model: maxNSmass3_0, total: 226474.82022042107\n",
      "DCO: BHNS, Model: noPISN, total: 197169.89410416505\n",
      "DCO: BHNS, Model: ccSNkick_100km_s, total: 521927.5480832839\n",
      "DCO: BHNS, Model: ccSNkick_30km_s, total: 978546.9836309865\n",
      "DCO: BHNS, Model: noBHkick, total: 803771.6969967576\n",
      "DCO: BHNS, Model: wolf_rayet_multiplier_0_1, total: 227499.79160484424\n",
      "DCO: BHNS, Model: wolf_rayet_multiplier_5, total: 35340.921948027644\n",
      "DCO: NSNS, Model: fiducial, total: 106989.40564324663\n",
      "DCO: NSNS, Model: massTransferEfficiencyFixed_0_25, total: 44379.182409191126\n",
      "DCO: NSNS, Model: massTransferEfficiencyFixed_0_5, total: 45697.006905214446\n",
      "DCO: NSNS, Model: massTransferEfficiencyFixed_0_75, total: 138684.82188862958\n",
      "DCO: NSNS, Model: unstableCaseBB, total: 1263.4732385115267\n",
      "DCO: NSNS, Model: alpha0_5, total: 60220.02160488234\n",
      "DCO: NSNS, Model: alpha2_0, total: 251381.87935678635\n",
      "DCO: NSNS, Model: optimistic, total: 139444.44865632558\n",
      "DCO: NSNS, Model: rapid, total: 91809.83542604158\n",
      "DCO: NSNS, Model: maxNSmass2_0, total: 104033.00869701641\n",
      "DCO: NSNS, Model: maxNSmass3_0, total: 109532.13642781148\n",
      "DCO: NSNS, Model: noPISN, total: 106978.8470568655\n",
      "DCO: NSNS, Model: ccSNkick_100km_s, total: 194153.6124803703\n",
      "DCO: NSNS, Model: ccSNkick_30km_s, total: 491978.3409323942\n",
      "DCO: NSNS, Model: noBHkick, total: 107999.37686159267\n",
      "DCO: NSNS, Model: wolf_rayet_multiplier_0_1, total: 101908.09909698443\n",
      "DCO: NSNS, Model: wolf_rayet_multiplier_5, total: 74924.39757796477\n"
     ]
    }
   ],
   "source": [
    "btypes = [\"BHBH\", \"BHNS\", \"NSNS\"]\n",
    "models = [v[\"file\"] for v in variations]\n",
    "\n",
    "totals = np.zeros(shape=(len(btypes), len(models)))\n",
    "\n",
    "for i in range(len(btypes)):\n",
    "    for j in range(len(models)):\n",
    "        totals[i][j] = get_total_DCO_in_MW(model=models[j], binary_type=btypes[i], w_Z=w_Z,\n",
    "                                           f_mass_sampled=f_mass_sampled,\n",
    "                                           average_mass_COMPAS=average_mass_COMPAS)\n",
    "        print(\"DCO: {}, Model: {}, total: {}\".format(btypes[i], models[j], totals[i][j]))\n",
    "\n",
    "np.save(\"../data/total_DCO_in_MW_temp.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

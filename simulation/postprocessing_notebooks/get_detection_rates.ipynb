{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aerial-glucose",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:50px; text-align:center\">DCO Detections</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "grateful-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import legwork\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from variations import variations\n",
    "from galaxy import simulate_mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "existing-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('font', family='serif')\n",
    "fs = 20\n",
    "\n",
    "params = {'legend.fontsize': fs,\n",
    "         'axes.labelsize': fs,\n",
    "         'xtick.labelsize':0.7*fs,\n",
    "         'ytick.labelsize':0.7*fs}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "employed-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "dco_colours = {\"BHBH\": plt.get_cmap(\"plasma\")(0.2), \n",
    "               \"BHNS\": plt.get_cmap(\"plasma\")(0.5),\n",
    "               \"NSNS\": plt.get_cmap(\"plasma\")(0.8)}\n",
    "\n",
    "dco_types = [\"BHBH\", \"BHNS\", \"NSNS\"]\n",
    "data_path = \"../data/\"\n",
    "sim_folder = data_path + \"simulation/\"  #\"../data/old_sims/simulation_plus_supp/\"\n",
    "\n",
    "total_DCOs_in_MW = np.load(data_path + \"total_DCO_in_MW.npy\")\n",
    "total_bound_DCOs_in_MW = np.load(data_path + \"total_DCO_in_MW_nohubble.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-kansas",
   "metadata": {},
   "source": [
    "# Calculate number of detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "passive-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(dco_type, MW_SIZE=100000, MW_MASS_FAC=1.5, t_obs=4*u.yr, only_frac=False):\n",
    "    # set up arrays for return\n",
    "    detections = np.zeros(shape=(len(dco_types), len(variations), 2500))\n",
    "    \n",
    "    # go through each physics variation\n",
    "#     for d in range(len(dco_types)):\n",
    "    \n",
    "    for d in range(len(dco_types)):\n",
    "        for v in range(len(variations)):\n",
    "            # open the proper output file\n",
    "            fname = sim_folder + \"{}_{}_all.h5\".format(dco_types[d], variations[v][\"file\"])\n",
    "            if os.path.isfile(fname):\n",
    "                with h5.File(fname, \"r\") as f:\n",
    "                    n_ten_year = f[\"simulation\"].attrs[\"n_ten_year\"].astype(np.int)\n",
    "                    total_mw_weight = f[\"simulation\"].attrs[\"total_MW_weight\"]\n",
    "                    full_data = f[\"simulation\"][...].squeeze()\n",
    "                \n",
    "#                 circ_sources = legwork.source.Source(m_1=full_data[\"m_1\"] * u.Msun, m_2=full_data[\"m_2\"] * u.Msun,\n",
    "#                                            dist=full_data[\"dist\"] * u.kpc, ecc=np.zeros(len(full_data[\"m_1\"])),\n",
    "#                                            a=full_data[\"a_LISA\"] * u.AU)\n",
    "#                 circ_snr = circ_sources.get_snr()\n",
    "                \n",
    "#                 print(dco_types[d])\n",
    "#                 true_rate = np.sum(full_data[\"weight\"][full_data[\"snr\"] >= 7]) / np.sum(total_mw_weight) * total_DCOs_in_MW[d][v] * MW_MASS_FAC\n",
    "#                 circ_rate = np.sum(full_data[\"weight\"][circ_snr >= 7]) / np.sum(total_mw_weight) * total_DCOs_in_MW[d][v] * MW_MASS_FAC\n",
    "#                 print(true_rate, circ_rate, (true_rate - circ_rate) / true_rate)\n",
    "#                 print()\n",
    "\n",
    "                # go through the file and normalise the detections for all binaries with SNR > x\n",
    "                cursor = 0\n",
    "                detections_per_MW = np.zeros(len(n_ten_year))\n",
    "                \n",
    "                checks = np.zeros(len(n_ten_year))\n",
    "                for i in range(len(n_ten_year)):\n",
    "                    snr = full_data[\"snr\"][cursor:cursor + n_ten_year[i]]\n",
    "                    weights = full_data[\"weight\"][cursor:cursor + n_ten_year[i]]\n",
    "                    checks = np.sum(weights)**2 / np.sum(weights**2)\n",
    "                    detections[d][v][i] = np.sum(weights[snr * np.sqrt(t_obs / (4 * u.yr)) > 7]) / total_mw_weight[i]\n",
    "                    cursor += n_ten_year[i]\n",
    "                if not only_frac:\n",
    "                    detections[d][v] *= total_DCOs_in_MW[d][v] * MW_MASS_FAC\n",
    "\n",
    "            # set to zero if no file exists (simulation will have crashed)\n",
    "            else:\n",
    "                detections[d][v] = 0\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections_alt(dco_type, MW_SIZE=100000, MW_MASS_FAC=1.5, t_obs=4*u.yr, only_frac=False):\n",
    "    # set up arrays for return\n",
    "    detections = np.zeros(shape=(len(dco_types), len(variations), 2500))\n",
    "    \n",
    "    fname = sim_folder + \"{}_{}_all.h5\".format(dco_types[dco_type], variations[0][\"file\"])\n",
    "    if os.path.isfile(fname):\n",
    "        with h5.File(fname, \"r\") as f:\n",
    "            total_mw_weight = f[\"simulation\"].attrs[\"total_MW_weight\"].sum()\n",
    "            full_data = f[\"simulation\"][...].squeeze()\n",
    "            \n",
    "        factor = total_DCOs_in_MW[dco_type][0] * MW_MASS_FAC / total_mw_weight\n",
    "        \n",
    "        weights = full_data[\"weight\"][full_data[\"snr\"] > 7]\n",
    "        avg = weights.sum() * factor\n",
    "        print(avg)\n",
    "        \n",
    "    sample_rates = np.zeros(1000)\n",
    "    for i in range(len(sample_rates)):\n",
    "        sample = np.random.choice(weights, len(weights), replace=True)\n",
    "        sample_rates[i] = sample.sum() * factor\n",
    "        \n",
    "    print(np.percentile(sample_rates, [5, 95]))\n",
    "    \n",
    "    sample_rates = np.zeros(1000)\n",
    "    for i in range(len(sample_rates)):\n",
    "        sample = np.random.choice(weights, 100, replace=True)\n",
    "        sample_rates[i] = sample.sum() * factor * (len(weights) / 100)\n",
    "        \n",
    "    print(np.percentile(sample_rates, [5, 95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "sitting-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_4yr = get_detections(dco_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "simplified-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.70766953242095\n",
      "4.6358057473799406\n",
      "32.84556507740563\n",
      "11.434237587159709\n",
      "8.358122307523175\n",
      "14.564530957325884\n"
     ]
    }
   ],
   "source": [
    "detections_10yr = get_detections(dco_types, t_obs=10*u.yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "plastic-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.70766953242095\n",
      "4.6358057473799406\n",
      "32.84556507740563\n",
      "11.434237587159709\n",
      "8.358122307523175\n",
      "14.564530957325884\n"
     ]
    }
   ],
   "source": [
    "detections_only_fractions = get_detections(dco_types, only_frac=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "behavioral-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/detections_4yr\", detections_4yr)\n",
    "np.save(\"../data/detections_10yr\", detections_10yr)\n",
    "np.save(\"../data/detections_only_fractions\", detections_only_fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-selling",
   "metadata": {},
   "source": [
    "# What if we assumed everything was circular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "enclosed-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_sources = [None, None, None]\n",
    "for i in range(len(dco_types)):\n",
    "    with h5.File(sim_folder + \"{}_fiducial_all.h5\".format(dco_types[i]), \"r\") as f:\n",
    "        full_data = f[\"simulation\"][...].squeeze()\n",
    "        snr_mask = full_data[\"snr\"] > 7\n",
    "        \n",
    "        data = full_data[snr_mask]\n",
    "        \n",
    "    fid_sources[i] = legwork.source.Source(m_1=data[\"m_1\"] * u.Msun, m_2=data[\"m_2\"] * u.Msun,\n",
    "                                           dist=data[\"dist\"] * u.kpc, ecc=data[\"e_LISA\"],\n",
    "                                           a=data[\"a_LISA\"] * u.AU)\n",
    "    fid_sources[i].weight = data[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "subject-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SNR for 46424 sources\n",
      "\t46421 sources are stationary\n",
      "\t\t30416 sources are stationary and circular\n",
      "\t\t16005 sources are stationary and eccentric\n",
      "\t3 sources are evolving\n",
      "\t\t3 sources are evolving and circular\n",
      "Calculating SNR for 46424 sources\n",
      "\t46421 sources are stationary\n",
      "\t\t46421 sources are stationary and circular\n",
      "\t3 sources are evolving\n",
      "\t\t3 sources are evolving and circular\n",
      "0.7607342497723641\n",
      "Calculating SNR for 44927 sources\n",
      "\t44925 sources are stationary\n",
      "\t\t41843 sources are stationary and circular\n",
      "\t\t3082 sources are stationary and eccentric\n",
      "\t2 sources are evolving\n",
      "\t\t2 sources are evolving and circular\n",
      "Calculating SNR for 44927 sources\n",
      "\t44925 sources are stationary\n",
      "\t\t44925 sources are stationary and circular\n",
      "\t2 sources are evolving\n",
      "\t\t2 sources are evolving and circular\n",
      "0.8955950229445685\n",
      "Calculating SNR for 32805 sources\n",
      "\t32803 sources are stationary\n",
      "\t\t18591 sources are stationary and circular\n",
      "\t\t14212 sources are stationary and eccentric\n",
      "\t2 sources are evolving\n",
      "\t\t2 sources are evolving and circular\n",
      "Calculating SNR for 32805 sources\n",
      "\t32803 sources are stationary\n",
      "\t\t32803 sources are stationary and circular\n",
      "\t2 sources are evolving\n",
      "\t\t2 sources are evolving and circular\n",
      "0.7993138018869117\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dco_types)):\n",
    "    snr_true = fid_sources[i].get_snr(verbose=True)\n",
    "    new_source = fid_sources[i]\n",
    "    new_source.ecc = np.zeros(new_source.n_sources)\n",
    "    snr_circ = new_source.get_snr(verbose=True)\n",
    "    \n",
    "    print(np.sum(new_source.weight[snr_circ > 7]) / np.sum(new_source.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "independent-shareware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SNR for 46424 sources\n",
      "\t46421 sources are stationary\n",
      "\t\t30416 sources are stationary and circular\n",
      "\t\t16005 sources are stationary and eccentric\n",
      "\t3 sources are evolving\n",
      "\t\t3 sources are evolving and circular\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "combined-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SNR for 46424 sources\n",
      "\t46421 sources are stationary\n",
      "\t\t46421 sources are stationary and circular\n",
      "\t3 sources are evolving\n",
      "\t\t3 sources are evolving and circular\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "coordinate-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993107013613648"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snr_true[snr_true > 7]) / len(snr_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "focused-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934904359813889"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snr_circ[snr_circ > 7]) / len(snr_circ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
